{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-data-augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32-zMt7tZr3R"
      },
      "source": [
        "# Image Data Augmentation\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/computer-vision-with-embedded-machine-learning/blob/master/2.3.2%20-%20Data%20Augmentation/image_data_augmentation.ipynb)\n",
        "\n",
        "Run this notebook to create a new dataset of augmented images from your original dataset.\n",
        "\n",
        "Create a folder named \"dataset\" in the /content directory and upload your images there. The images should be divided into their respective classes, where each class has its own folder with the name of the class. For example:\n",
        "\n",
        "<pre>\n",
        "/content\n",
        "    |- dataset\n",
        "        |- background\n",
        "        |- capacitor\n",
        "        |- diode\n",
        "        |- led\n",
        "        |- resistor\n",
        "</pre>\n",
        "\n",
        "The original images along with their transforms will be saved in the output directory. Each output file will be the original filename appended with \"_{num}\" where {num} is some incrementing value based on the total number of transforms performed per image.\n",
        "\n",
        "For example, if you have a file named \"0.png\" in /content/dataset/resistor, it will become \"0_0.png\" in /content/output/resistor. The first transform will be \"0_1.png\", the second transform will be \"0_2.png\" and so on.\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: June 21, 2021<br>\n",
        "License: [Apache-2.0](apache.org/licenses/LICENSE-2.0)<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTimcB-ZoIT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "import skimage.transform\n",
        "import skimage.util"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJCNZmEaCCN"
      },
      "source": [
        "### Settings\n",
        "\n",
        "# Location of dataset and output folder\n",
        "DATASET_PATH = \"/content/dataset\"\n",
        "OUT_PATH = \"/content/output\"\n",
        "OUT_ZIP = \"augmented_dataset.zip\"\n",
        "\n",
        "# File format to use for new dataset\n",
        "IMG_EXT = \".png\"\n",
        "\n",
        "# Rotations (degrees)\n",
        "ROTATIONS = [45, 90, 135]\n",
        "\n",
        "# Random zoom settings\n",
        "SCALE_FACTOR = 1.3    # Must be >= 1.0\n",
        "NUM_CROPS = 2\n",
        "\n",
        "# Random translation settings\n",
        "NUM_TRANSLATIONS = 2\n",
        "\n",
        "# Types of noise to add\n",
        "NOISE_TYPES = ['gaussian', 's&p']\n",
        "\n",
        "# You are welcome to change the seed to get different augmentation effects\n",
        "SEED = 42\n",
        "random.seed(SEED)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siLr8t4-qR9K",
        "outputId": "67d6fb24-b976-41c5-f329-fb9092902dd2"
      },
      "source": [
        "### Create output directory\n",
        "try:\n",
        "  os.makedirs(OUT_PATH)\n",
        "except FileExistsError:\n",
        "  print(\"WARNING: Output directory already exists. Check to make sure it is empty.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Output directory already exists. Check to make sure it is empty.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAZYWLFeB9vR"
      },
      "source": [
        "## The various transform Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxh8f4JXgnTa"
      },
      "source": [
        "### Function to create 3 new flipped images of the input\n",
        "def create_flipped(img):\n",
        "\n",
        "  # Create a list of flipped images\n",
        "  flipped = []\n",
        "  flipped.append(np.fliplr(img))\n",
        "  flipped.append(np.flipud(img))\n",
        "  flipped.append(np.flipud(np.fliplr(img)))\n",
        "\n",
        "  return flipped"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96_3m50XhDww"
      },
      "source": [
        "### Function to create new rotated images of the input\n",
        "def create_rotated(img, rotations):\n",
        "\n",
        "  # Create list of rotated images (keep 8-bit values)\n",
        "  rotated = []\n",
        "  for rot in rotations:\n",
        "    img_rot = skimage.transform.rotate(img, angle=rot, mode='edge', preserve_range=True)\n",
        "    img_rot = img_rot.astype(np.uint8)\n",
        "    rotated.append(img_rot)\n",
        "\n",
        "  return rotated"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNmLBQtmg9rT"
      },
      "source": [
        "### Function to create random scale/crop (zoom) images\n",
        "def create_random_zooms(img, scale_factor, num_crops):\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create scaled images (e.g. make the image bigger) and keep 8-bit values\n",
        "  img_scaled = skimage.transform.rescale(img, \n",
        "                                        scale=scale_factor, \n",
        "                                        anti_aliasing=True, \n",
        "                                        multichannel=True,\n",
        "                                        preserve_range=True)\n",
        "  img_scaled = img_scaled.astype(np.uint8)\n",
        "\n",
        "  # Get height and width of scaled image\n",
        "  s_h = img_scaled.shape[0]\n",
        "  s_w = img_scaled.shape[1]\n",
        "\n",
        "  # Create list of random zooms\n",
        "  zooms = []\n",
        "  for i in range(num_crops):\n",
        "    \n",
        "    # Randomly choose start of crop point\n",
        "    crop_y = round(random.random() * (s_h - height))\n",
        "    crop_x = round(random.random() * (s_w - width))\n",
        "\n",
        "    # Crop scaled image\n",
        "    zoom = img_scaled[crop_y:(crop_y + height), crop_x:(crop_x + width), :]\n",
        "\n",
        "    # Append zoomed image to list\n",
        "    zooms.append(zoom)\n",
        "\n",
        "  return zooms"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b55wy1q69-xY"
      },
      "source": [
        "### Function to create a random set of translated images (no more than 1/4 of width or height away)\n",
        "def create_random_translations(img, num_translations):\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create list of random translations\n",
        "  translations = []\n",
        "  for i in range(num_translations):\n",
        "  \n",
        "    # Choose random amount to translate (up to 1/4 image width, height) in either direction\n",
        "    tr_y = round((0.5 - random.random()) * (height / 2))\n",
        "    tr_x = round((0.5 - random.random()) * (width / 2))\n",
        "\n",
        "    # Perform translation to create new image\n",
        "    translation = skimage.transform.AffineTransform(translation=(tr_y, tr_x))\n",
        "    img_tr = skimage.transform.warp(img, translation, mode='edge', preserve_range=True)\n",
        "    img_tr = img_tr.astype(np.uint8)\n",
        "\n",
        "    # Append translated image to list\n",
        "    translations.append(img_tr)\n",
        "\n",
        "  return translations"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad0IR6Pc_n9b"
      },
      "source": [
        "### Function to add random noise to images\n",
        "def create_noisy(img, types, seed=None):\n",
        "\n",
        "  # Add noise of different types\n",
        "  noisy_imgs = []\n",
        "  for t in types:\n",
        "    noise = skimage.util.random_noise(img, mode=t, seed=seed)\n",
        "    noise = (noise * 255).astype(np.uint8)\n",
        "    noisy_imgs.append(noise)\n",
        "\n",
        "  return noisy_imgs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaJR7hAOCEID"
      },
      "source": [
        "## Create transforms and save as new files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ryKQeQaOKE"
      },
      "source": [
        "### Function to open image and create a list of new transforms\n",
        "def create_transforms(file_path):\n",
        "\n",
        "  # Open the image\n",
        "  img = PIL.Image.open(file_path)\n",
        "\n",
        "  # Convert the image to a Numpy array (keep all color channels)\n",
        "  img_array = np.asarray(img)\n",
        "\n",
        "  # Add original image to front of list\n",
        "  img_tfs = []\n",
        "  img_tfs.append([img_array])\n",
        "\n",
        "  # Perform transforms\n",
        "  img_tfs.append(create_flipped(img_array))\n",
        "  img_tfs.append(create_rotated(img_array, ROTATIONS))\n",
        "  img_tfs.append(create_random_zooms(img_array, SCALE_FACTOR, NUM_CROPS))\n",
        "  img_tfs.append(create_random_translations(img_array, NUM_TRANSLATIONS))\n",
        "  img_tfs.append(create_noisy(img_array, NOISE_TYPES, SEED))\n",
        "\n",
        "  # Flatten list of lists (to create one long list of images)\n",
        "  img_tfs = [img for img_list in img_tfs for img in img_list]\n",
        "\n",
        "  return img_tfs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYI0iVgudcrh"
      },
      "source": [
        "### Create all transforms\n",
        "\n",
        "label_dir = \"resistor\"\n",
        "filename = \"0.bmp\"\n",
        "\n",
        "# Get the root of the filename before the extension\n",
        "file_root = os.path.splitext(filename)[0]\n",
        "\n",
        "# Create output directory\n",
        "out_path = os.path.join(OUT_PATH, label_dir)\n",
        "os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "# Do all transforms\n",
        "file_path = os.path.join(DATASET_PATH, label_dir, filename)\n",
        "img_tfs = create_transforms(file_path)\n",
        "\n",
        "# Save images to new files in output directory\n",
        "for i, img in enumerate(img_tfs):\n",
        "\n",
        "  # Create a Pillow image from the Numpy array\n",
        "  img_pil = PIL.Image.fromarray(img)\n",
        "\n",
        "  # Construct filename (<orignal>_<transform_num>.<EXT>)\n",
        "  out_file_path = os.path.join(out_path, file_root + \"_\" + str(i) + IMG_EXT)\n",
        "\n",
        "  # Convert Numpy array to image and save as a file\n",
        "  img_pil = PIL.Image.fromarray(img)\n",
        "  img_pil.save(out_file_path)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3ZEsAGUAvUS"
      },
      "source": [
        "### Load all images, create transforms, and save in output directory\n",
        "\n",
        "# Find the directories in the dataset folder (skip the Jupyter Notebook checkpoints hidden folder)\n",
        "for label in os.listdir(DATASET_PATH):\n",
        "  class_dir = os.path.join(DATASET_PATH, label)\n",
        "  if os.path.isdir(class_dir) and label != \".ipynb_checkpoints\":\n",
        "\n",
        "    # Create output directory\n",
        "    out_path = os.path.join(OUT_PATH, label)\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    # Go through each image in the subfolder\n",
        "    for i, filename in enumerate(os.listdir(class_dir)):\n",
        "\n",
        "      # Skip the Jupyter Notebook checkpoints folder that sometimes gets added\n",
        "      if filename != \".ipynb_checkpoints\":\n",
        "\n",
        "        # Get the root of the filename before the extension\n",
        "        file_root = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Do all transforms for that one image\n",
        "        file_path = os.path.join(DATASET_PATH, label, filename)\n",
        "        img_tfs = create_transforms(file_path)\n",
        "\n",
        "        # Save images to new files in output directory\n",
        "        for i, img in enumerate(img_tfs):\n",
        "\n",
        "          # Create a Pillow image from the Numpy array\n",
        "          img_pil = PIL.Image.fromarray(img)\n",
        "\n",
        "          # Construct filename (<orignal>_<transform_num>.<EXT>)\n",
        "          out_file_path = os.path.join(out_path, file_root + \"_\" + str(i) + IMG_EXT)\n",
        "\n",
        "          # Convert Numpy array to image and save as a file\n",
        "          img_pil = PIL.Image.fromarray(img)\n",
        "          img_pil.save(out_file_path)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWwxvzKxDJ18"
      },
      "source": [
        "### Zip our new dataset (use '!' to call Linux commands)\n",
        "!zip -r -q \"{OUT_ZIP}\" \"{OUT_PATH}\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWKxSWL3Hh2y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}